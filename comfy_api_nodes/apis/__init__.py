# generated by datamodel-codegen:
#   filename:  filtered-openapi.yaml
#   timestamp: 2025-04-29T19:38:18+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import AnyUrl, BaseModel, Field, RootModel


class ErrorResponse(BaseModel):
    error: str
    message: str


class ImageRequest(BaseModel):
    prompt: str = Field(
        ..., description='Required. The prompt to use to generate the image.'
    )
    aspect_ratio: Optional[str] = Field(
        None,
        description="Optional. The aspect ratio (e.g., 'ASPECT_16_9', 'ASPECT_1_1'). Cannot be used with resolution. Defaults to 'ASPECT_1_1' if unspecified.",
    )
    model: str = Field(..., description="The model used (e.g., 'V_2', 'V_2A_TURBO')")
    magic_prompt_option: Optional[str] = Field(
        None, description="Optional. MagicPrompt usage ('AUTO', 'ON', 'OFF')."
    )
    seed: Optional[int] = Field(
        None,
        description='Optional. A number between 0 and 2147483647.',
        ge=0,
        le=2147483647,
    )
    style_type: Optional[str] = Field(
        None,
        description="Optional. Style type ('AUTO', 'GENERAL', 'REALISTIC', 'DESIGN', 'RENDER_3D', 'ANIME'). Only for models V_2 and above.",
    )
    negative_prompt: Optional[str] = Field(
        None,
        description='Optional. Description of what to exclude. Only for V_1, V_1_TURBO, V_2, V_2_TURBO.',
    )
    num_images: Optional[int] = Field(
        1,
        description='Optional. Number of images to generate (1-8). Defaults to 1.',
        ge=1,
        le=8,
    )
    resolution: Optional[str] = Field(
        None,
        description="Optional. Resolution (e.g., 'RESOLUTION_1024_1024'). Only for model V_2. Cannot be used with aspect_ratio.",
    )
    color_palette: Optional[Dict[str, Any]] = Field(
        None, description='Optional. Color palette object. Only for V_2, V_2_TURBO.'
    )


class IdeogramGenerateRequest(BaseModel):
    image_request: ImageRequest = Field(
        ..., description='The image generation request parameters.'
    )


class Datum(BaseModel):
    prompt: Optional[str] = Field(
        None, description='The prompt used to generate this image.'
    )
    resolution: Optional[str] = Field(
        None, description="The resolution of the generated image (e.g., '1024x1024')."
    )
    is_image_safe: Optional[bool] = Field(
        None, description='Indicates whether the image is considered safe.'
    )
    seed: Optional[int] = Field(
        None, description='The seed value used for this generation.'
    )
    url: Optional[str] = Field(None, description='URL to the generated image.')
    style_type: Optional[str] = Field(
        None,
        description="The style type used for generation (e.g., 'REALISTIC', 'ANIME').",
    )


class IdeogramGenerateResponse(BaseModel):
    created: Optional[datetime] = Field(
        None, description='Timestamp when the generation was created.'
    )
    data: Optional[List[Datum]] = Field(
        None, description='Array of generated image information.'
    )


class ModelName(str, Enum):
    kling_v1 = 'kling-v1'
    kling_v1_6 = 'kling-v1-6'


class Mode(str, Enum):
    std = 'std'
    pro = 'pro'


class Type(str, Enum):
    simple = 'simple'
    down_back = 'down_back'
    forward_up = 'forward_up'
    right_turn_forward = 'right_turn_forward'
    left_turn_forward = 'left_turn_forward'


class Config(BaseModel):
    horizontal: Optional[float] = Field(None, ge=-10.0, le=10.0)
    vertical: Optional[float] = Field(None, ge=-10.0, le=10.0)
    pan: Optional[float] = Field(None, ge=-10.0, le=10.0)
    tilt: Optional[float] = Field(None, ge=-10.0, le=10.0)
    roll: Optional[float] = Field(None, ge=-10.0, le=10.0)
    zoom: Optional[float] = Field(None, ge=-10.0, le=10.0)


class CameraControl(BaseModel):
    type: Optional[Type] = Field(None, description='Predefined camera movements type')
    config: Optional[Config] = None


class AspectRatio(str, Enum):
    field_16_9 = '16:9'
    field_9_16 = '9:16'
    field_1_1 = '1:1'


class Duration(str, Enum):
    field_5 = '5'
    field_10 = '10'


class KlingText2VideoRequest(BaseModel):
    model_name: Optional[ModelName] = Field('kling-v1', description='Model Name')
    prompt: Optional[str] = Field(
        None, description='Positive text prompt', max_length=2500
    )
    negative_prompt: Optional[str] = Field(
        None, description='Negative text prompt', max_length=2500
    )
    cfg_scale: Optional[float] = Field(
        0.5, description='Flexibility in video generation', ge=0.0, le=1.0
    )
    mode: Optional[Mode] = Field('std', description='Video generation mode')
    camera_control: Optional[CameraControl] = None
    aspect_ratio: Optional[AspectRatio] = '16:9'
    duration: Optional[Duration] = '5'
    callback_url: Optional[AnyUrl] = Field(
        None, description='The callback notification address'
    )
    external_task_id: Optional[str] = Field(None, description='Customized Task ID')


class TaskStatus(str, Enum):
    submitted = 'submitted'
    processing = 'processing'
    succeed = 'succeed'
    failed = 'failed'


class TaskInfo(BaseModel):
    external_task_id: Optional[str] = None


class Video(BaseModel):
    id: Optional[str] = Field(None, description='Generated video ID')
    url: Optional[AnyUrl] = Field(None, description='URL for generated video')
    duration: Optional[str] = Field(None, description='Total video duration')


class TaskResult(BaseModel):
    videos: Optional[List[Video]] = None


class Data(BaseModel):
    task_id: Optional[str] = Field(None, description='Task ID')
    task_status: Optional[TaskStatus] = None
    task_info: Optional[TaskInfo] = None
    created_at: Optional[int] = Field(None, description='Task creation time')
    updated_at: Optional[int] = Field(None, description='Task update time')
    task_result: Optional[TaskResult] = None


class KlingText2VideoResponse(BaseModel):
    code: Optional[int] = Field(None, description='Error code')
    message: Optional[str] = Field(None, description='Error message')
    request_id: Optional[str] = Field(None, description='Request ID')
    data: Optional[Data] = None


class ModelName1(str, Enum):
    kling_v1 = 'kling-v1'
    kling_v1_5 = 'kling-v1-5'
    kling_v1_6 = 'kling-v1-6'


class Trajectory(BaseModel):
    x: Optional[int] = Field(
        None,
        description='The horizontal coordinate of trajectory point. Based on bottom-left corner of image as origin (0,0).',
    )
    y: Optional[int] = Field(
        None,
        description='The vertical coordinate of trajectory point. Based on bottom-left corner of image as origin (0,0).',
    )


class DynamicMask(BaseModel):
    mask: Optional[AnyUrl] = Field(
        None,
        description='Dynamic Brush Application Area (Mask image created by users using the motion brush). The aspect ratio must match the input image.',
    )
    trajectories: Optional[List[Trajectory]] = None


class Config1(BaseModel):
    horizontal: Optional[float] = Field(
        None,
        description="Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right.",
        ge=-10.0,
        le=10.0,
    )
    vertical: Optional[float] = Field(
        None,
        description="Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward.",
        ge=-10.0,
        le=10.0,
    )
    pan: Optional[float] = Field(
        None,
        description="Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation.",
        ge=-10.0,
        le=10.0,
    )
    tilt: Optional[float] = Field(
        None,
        description="Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation.",
        ge=-10.0,
        le=10.0,
    )
    roll: Optional[float] = Field(
        None,
        description="Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise.",
        ge=-10.0,
        le=10.0,
    )
    zoom: Optional[float] = Field(
        None,
        description="Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view.",
        ge=-10.0,
        le=10.0,
    )


class CameraControl1(BaseModel):
    type: Optional[Type] = Field(
        None,
        description='Predefined camera movements type. simple: Customizable camera movement. down_back: Camera descends and moves backward. forward_up: Camera moves forward and tilts up. right_turn_forward: Rotate right and move forward. left_turn_forward: Rotate left and move forward.',
    )
    config: Optional[Config1] = None


class KlingImage2VideoRequest(BaseModel):
    model_name: Optional[ModelName1] = Field('kling-v1', description='Model Name')
    image: Optional[str] = Field(
        None,
        description='Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix.',
    )
    image_tail: Optional[str] = Field(
        None,
        description='Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix.',
    )
    prompt: Optional[str] = Field(
        None, description='Positive text prompt', max_length=2500
    )
    negative_prompt: Optional[str] = Field(
        None, description='Negative text prompt', max_length=2500
    )
    cfg_scale: Optional[float] = Field(
        0.5,
        description="Flexibility in video generation. The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
        ge=0.0,
        le=1.0,
    )
    mode: Optional[Mode] = Field(
        'std',
        description='Video generation mode. std: Standard Mode, which is cost-effective. pro: Professional Mode, generates videos with longer duration but higher quality output.',
    )
    static_mask: Optional[AnyUrl] = Field(
        None,
        description='Static Brush Application Area (Mask image created by users using the motion brush). The aspect ratio must match the input image.',
    )
    dynamic_masks: Optional[List[DynamicMask]] = Field(
        None,
        description='Dynamic Brush Configuration List (up to 6 groups). For 5-second videos, trajectory length must not exceed 77 coordinates.',
    )
    camera_control: Optional[CameraControl1] = None
    aspect_ratio: Optional[AspectRatio] = '16:9'
    duration: Optional[Duration] = Field('5', description='Video length in seconds')
    callback_url: Optional[AnyUrl] = Field(
        None,
        description='The callback notification address. Server will notify when the task status changes.',
    )
    external_task_id: Optional[str] = Field(
        None,
        description='Customized Task ID. Must be unique within a single user account.',
    )


class TaskResult1(BaseModel):
    videos: Optional[List[Video]] = None


class Data1(BaseModel):
    task_id: Optional[str] = Field(None, description='Task ID')
    task_status: Optional[TaskStatus] = None
    task_info: Optional[TaskInfo] = None
    created_at: Optional[int] = Field(None, description='Task creation time')
    updated_at: Optional[int] = Field(None, description='Task update time')
    task_result: Optional[TaskResult1] = None


class KlingImage2VideoResponse(BaseModel):
    code: Optional[int] = Field(None, description='Error code')
    message: Optional[str] = Field(None, description='Error message')
    request_id: Optional[str] = Field(None, description='Request ID')
    data: Optional[Data1] = None


class Model(str, Enum):
    T2V_01_Director = 'T2V-01-Director'
    I2V_01_Director = 'I2V-01-Director'
    S2V_01 = 'S2V-01'
    I2V_01 = 'I2V-01'
    I2V_01_live = 'I2V-01-live'
    T2V_01 = 'T2V-01'


class SubjectReferenceItem(BaseModel):
    image: Optional[str] = Field(
        None, description='URL or base64 encoding of the subject reference image.'
    )
    mask: Optional[str] = Field(
        None,
        description='URL or base64 encoding of the mask for the subject reference image.',
    )


class MinimaxVideoGenerationRequest(BaseModel):
    model: Model = Field(
        ...,
        description='Required. ID of model. Options: T2V-01-Director, I2V-01-Director, S2V-01, I2V-01, I2V-01-live, T2V-01',
    )
    prompt: Optional[str] = Field(
        None,
        description='Description of the video. Should be less than 2000 characters. Supports camera movement instructions in [brackets].',
        max_length=2000,
    )
    prompt_optimizer: Optional[bool] = Field(
        True,
        description='If true (default), the model will automatically optimize the prompt. Set to false for more precise control.',
    )
    first_frame_image: Optional[str] = Field(
        None,
        description='URL or base64 encoding of the first frame image. Required when model is I2V-01, I2V-01-Director, or I2V-01-live.',
    )
    subject_reference: Optional[List[SubjectReferenceItem]] = Field(
        None,
        description='Only available when model is S2V-01. The model will generate a video based on the subject uploaded through this parameter.',
    )
    callback_url: Optional[str] = Field(
        None,
        description='Optional. URL to receive real-time status updates about the video generation task.',
    )


class MinimaxBaseResponse(BaseModel):
    status_code: int = Field(
        ...,
        description='Status code. 0 indicates success, other values indicate errors.',
    )
    status_msg: str = Field(
        ..., description='Specific error details or success message.'
    )


class MinimaxVideoGenerationResponse(BaseModel):
    task_id: str = Field(
        ..., description='The task ID for the asynchronous video generation task.'
    )
    base_resp: MinimaxBaseResponse


class File(BaseModel):
    file_id: Optional[int] = Field(None, description='Unique identifier for the file')
    bytes: Optional[int] = Field(None, description='File size in bytes')
    created_at: Optional[int] = Field(
        None, description='Unix timestamp when the file was created, in seconds'
    )
    filename: Optional[str] = Field(None, description='The name of the file')
    purpose: Optional[str] = Field(None, description='The purpose of using the file')
    download_url: Optional[str] = Field(
        None, description='The URL to download the video'
    )


class MinimaxFileRetrieveResponse(BaseModel):
    file: File
    base_resp: MinimaxBaseResponse


class Status(str, Enum):
    Queueing = 'Queueing'
    Preparing = 'Preparing'
    Processing = 'Processing'
    Success = 'Success'
    Fail = 'Fail'


class MinimaxTaskResultResponse(BaseModel):
    task_id: str = Field(..., description='The task ID being queried.')
    status: Status = Field(
        ...,
        description="Task status: 'Queueing' (in queue), 'Preparing' (task is preparing), 'Processing' (generating), 'Success' (task completed successfully), or 'Fail' (task failed).",
    )
    file_id: Optional[str] = Field(
        None,
        description='After the task status changes to Success, this field returns the file ID corresponding to the generated video.',
    )
    base_resp: MinimaxBaseResponse


class BFLFluxProGenerateRequest(BaseModel):
    prompt: str = Field(..., description='The text prompt for image generation.')
    negative_prompt: Optional[str] = Field(
        None, description='The negative prompt for image generation.'
    )
    width: int = Field(
        ..., description='The width of the image to generate.', ge=64, le=2048
    )
    height: int = Field(
        ..., description='The height of the image to generate.', ge=64, le=2048
    )
    num_inference_steps: Optional[int] = Field(
        None, description='The number of inference steps.', ge=1, le=100
    )
    guidance_scale: Optional[float] = Field(
        None, description='The guidance scale for generation.', ge=1.0, le=20.0
    )
    seed: Optional[int] = Field(None, description='The seed value for reproducibility.')
    num_images: Optional[int] = Field(
        None, description='The number of images to generate.', ge=1, le=4
    )


class BFLFluxProGenerateResponse(BaseModel):
    id: str = Field(..., description='The unique identifier for the generation task.')
    polling_url: str = Field(..., description='URL to poll for the generation result.')


class RecraftImageGenerationRequest(BaseModel):
    prompt: str = Field(
        ..., description='The text prompt describing the image to generate'
    )
    model: str = Field(
        ..., description='The model to use for generation (e.g., "recraftv3")'
    )
    style: Optional[str] = Field(
        None,
        description='The style to apply to the generated image (e.g., "digital_illustration")',
    )
    size: str = Field(
        ..., description='The size of the generated image (e.g., "1024x1024")'
    )
    n: int = Field(..., description='The number of images to generate', ge=1, le=4)


class Datum1(BaseModel):
    image_id: Optional[str] = Field(
        None, description='Unique identifier for the generated image'
    )
    url: Optional[str] = Field(None, description='URL to access the generated image')


class RecraftImageGenerationResponse(BaseModel):
    created: int = Field(
        ..., description='Unix timestamp when the generation was created'
    )
    credits: int = Field(..., description='Number of credits used for the generation')
    data: List[Datum1] = Field(..., description='Array of generated image information')


class KlingErrorResponse(BaseModel):
    code: int = Field(
        ...,
        description='- 1000: Authentication failed\n- 1001: Authorization is empty\n- 1002: Authorization is invalid\n- 1003: Authorization is not yet valid\n- 1004: Authorization has expired\n- 1100: Account exception\n- 1101: Account in arrears (postpaid scenario)\n- 1102: Resource pack depleted or expired (prepaid scenario)\n- 1103: Unauthorized access to requested resource\n- 1200: Invalid request parameters\n- 1201: Invalid parameters\n- 1202: Invalid request method\n- 1203: Requested resource does not exist\n- 1300: Trigger platform strategy\n- 1301: Trigger content security policy\n- 1302: API request too frequent\n- 1303: Concurrency/QPS exceeds limit\n- 1304: Trigger IP whitelist policy\n- 5000: Internal server error\n- 5001: Service temporarily unavailable\n- 5002: Server internal timeout\n',
    )
    message: str = Field(..., description='Human-readable error message')
    request_id: str = Field(
        ..., description='Request ID for tracking and troubleshooting'
    )


class Image(BaseModel):
    bytesBase64Encoded: str
    gcsUri: Optional[str] = None
    mimeType: Optional[str] = None


class Image1(BaseModel):
    bytesBase64Encoded: Optional[str] = None
    gcsUri: str
    mimeType: Optional[str] = None


class Instance(BaseModel):
    prompt: str = Field(..., description='Text description of the video')
    image: Optional[Union[Image, Image1]] = Field(
        None, description='Optional image to guide video generation'
    )


class PersonGeneration(str, Enum):
    ALLOW = 'ALLOW'
    BLOCK = 'BLOCK'


class Parameters(BaseModel):
    aspectRatio: Optional[str] = Field(None, examples=['16:9'])
    negativePrompt: Optional[str] = None
    personGeneration: Optional[PersonGeneration] = None
    sampleCount: Optional[int] = None
    seed: Optional[int] = None
    storageUri: Optional[str] = Field(
        None, description='Optional Cloud Storage URI to upload the video'
    )
    durationSeconds: Optional[int] = None
    enhancePrompt: Optional[bool] = None


class Veo2GenVidRequest(BaseModel):
    instances: Optional[List[Instance]] = None
    parameters: Optional[Parameters] = None


class Veo2GenVidResponse(BaseModel):
    name: str = Field(
        ...,
        description='Operation resource name',
        examples=[
            'projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/a1b07c8e-7b5a-4aba-bb34-3e1ccb8afcc8'
        ],
    )


class Veo2GenVidPollRequest(BaseModel):
    operationName: str = Field(
        ...,
        description='Full operation name (from predict response)',
        examples=[
            'projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/OPERATION_ID'
        ],
    )


class Video2(BaseModel):
    gcsUri: Optional[str] = Field(None, description='Cloud Storage URI of the video')
    bytesBase64Encoded: Optional[str] = Field(
        None, description='Base64-encoded video content'
    )
    mimeType: Optional[str] = Field(None, description='Video MIME type')


class Response(BaseModel):
    field_type: Optional[str] = Field(
        None,
        alias='@type',
        examples=[
            'type.googleapis.com/cloud.ai.large_models.vision.GenerateVideoResponse'
        ],
    )
    raiMediaFilteredCount: Optional[int] = Field(
        None, description='Count of media filtered by responsible AI policies'
    )
    videos: Optional[List[Video2]] = None


class Veo2GenVidPollResponse(BaseModel):
    name: Optional[str] = None
    done: Optional[bool] = None
    response: Optional[Response] = Field(
        None, description='The actual prediction response if done is true'
    )


class RunwayImageToVideoResponse(BaseModel):
    id: Optional[str] = Field(None, description='Task ID')


class RunwayTaskStatusEnum(str, Enum):
    SUCCEEDED = 'SUCCEEDED'
    RUNNING = 'RUNNING'
    FAILED = 'FAILED'
    PENDING = 'PENDING'
    CANCELLED = 'CANCELLED'
    THROTTLED = 'THROTTLED'


class RunwayModelEnum(str, Enum):
    gen4_turbo = 'gen4_turbo'
    gen3a_turbo = 'gen3a_turbo'


class Position(str, Enum):
    first = 'first'
    last = 'last'


class RunwayPromptImageDetailedObject(BaseModel):
    uri: str = Field(
        ..., description='A HTTPS URL or data URI containing an encoded image.'
    )
    position: Position = Field(
        ...,
        description="The position of the image in the output video. 'last' is currently supported for gen3a_turbo only.",
    )


class RunwayDurationEnum(int, Enum):
    integer_5 = 5
    integer_10 = 10


class RunwayAspectRatioEnum(str, Enum):
    field_1280_720 = '1280:720'
    field_720_1280 = '720:1280'
    field_1104_832 = '1104:832'
    field_832_1104 = '832:1104'
    field_960_960 = '960:960'
    field_1584_672 = '1584:672'
    field_1280_768 = '1280:768'
    field_768_1280 = '768:1280'


class RunwayPromptImageObject(
    RootModel[Union[str, List[RunwayPromptImageDetailedObject]]]
):
    root: Union[str, List[RunwayPromptImageDetailedObject]] = Field(
        ...,
        description='Image(s) to use for the video generation. Can be a single URI or an array of image objects with positions.',
    )


class Datum2(BaseModel):
    b64_json: Optional[str] = Field(None, description='Base64 encoded image data')
    url: Optional[str] = Field(None, description='URL of the image')
    revised_prompt: Optional[str] = Field(None, description='Revised prompt')


class InputTokensDetails(BaseModel):
    text_tokens: Optional[int] = None
    image_tokens: Optional[int] = None


class Usage(BaseModel):
    input_tokens: Optional[int] = None
    input_tokens_details: Optional[InputTokensDetails] = None
    output_tokens: Optional[int] = None
    total_tokens: Optional[int] = None


class OpenAIImageGenerationResponse(BaseModel):
    data: Optional[List[Datum2]] = None
    usage: Optional[Usage] = None


class Quality(str, Enum):
    low = 'low'
    medium = 'medium'
    high = 'high'
    standard = 'standard'
    hd = 'hd'


class OutputFormat(str, Enum):
    png = 'png'
    webp = 'webp'
    jpeg = 'jpeg'


class Moderation(str, Enum):
    low = 'low'
    auto = 'auto'


class Background(str, Enum):
    transparent = 'transparent'
    opaque = 'opaque'


class ResponseFormat(str, Enum):
    url = 'url'
    b64_json = 'b64_json'


class Style(str, Enum):
    vivid = 'vivid'
    natural = 'natural'


class OpenAIImageGenerationRequest(BaseModel):
    model: Optional[str] = Field(
        None, description='The model to use for image generation', examples=['dall-e-3']
    )
    prompt: str = Field(
        ...,
        description='A text description of the desired image',
        examples=['Draw a rocket in front of a blackhole in deep space'],
    )
    n: Optional[int] = Field(
        None,
        description='The number of images to generate (1-10). Only 1 supported for dall-e-3.',
        examples=[1],
    )
    quality: Optional[Quality] = Field(
        None, description='The quality of the generated image', examples=['high']
    )
    size: Optional[str] = Field(
        None,
        description='Size of the image (e.g., 1024x1024, 1536x1024, auto)',
        examples=['1024x1536'],
    )
    output_format: Optional[OutputFormat] = Field(
        None, description='Format of the output image', examples=['png']
    )
    output_compression: Optional[int] = Field(
        None, description='Compression level for JPEG or WebP (0-100)', examples=[100]
    )
    moderation: Optional[Moderation] = Field(
        None, description='Content moderation setting', examples=['auto']
    )
    background: Optional[Background] = Field(
        None, description='Background transparency', examples=['opaque']
    )
    response_format: Optional[ResponseFormat] = Field(
        None, description='Response format of image data', examples=['b64_json']
    )
    style: Optional[Style] = Field(
        None, description='Style of the image (only for dall-e-3)', examples=['vivid']
    )
    user: Optional[str] = Field(
        None,
        description='A unique identifier for end-user monitoring',
        examples=['user-1234'],
    )


class OpenAIImageEditRequest(BaseModel):
    model: str = Field(
        ..., description='The model to use for image editing', examples=['gpt-image-1']
    )
    prompt: str = Field(
        ...,
        description='A text description of the desired edit',
        examples=['Give the rocketship rainbow coloring'],
    )
    n: Optional[int] = Field(
        None, description='The number of images to generate', examples=[1]
    )
    quality: Optional[str] = Field(
        None, description='The quality of the edited image', examples=['low']
    )
    size: Optional[str] = Field(
        None, description='Size of the output image', examples=['1024x1024']
    )
    output_format: Optional[OutputFormat] = Field(
        None, description='Format of the output image', examples=['png']
    )
    output_compression: Optional[int] = Field(
        None, description='Compression level for JPEG or WebP (0-100)', examples=[100]
    )
    moderation: Optional[Moderation] = Field(
        None, description='Content moderation setting', examples=['auto']
    )
    background: Optional[str] = Field(
        None, description='Background transparency', examples=['opaque']
    )
    user: Optional[str] = Field(
        None,
        description='A unique identifier for end-user monitoring',
        examples=['user-1234'],
    )


class AspectRatio2(RootModel[float]):
    root: float = Field(
        ...,
        description='Aspect ratio (width / height)',
        ge=0.4,
        le=2.5,
        title='Aspectratio',
    )


class PikaBodyGenerate22T2vGenerate22T2vPost(BaseModel):
    promptText: str = Field(..., title='Prompttext')
    negativePrompt: Optional[str] = Field(None, title='Negativeprompt')
    seed: Optional[int] = Field(None, title='Seed')
    resolution: Optional[str] = Field('1080p', title='Resolution')
    duration: Optional[int] = Field(5, title='Duration')
    aspectRatio: Optional[AspectRatio2] = Field(
        None, description='Aspect ratio (width / height)', title='Aspectratio'
    )


class PikaGenerateResponse(BaseModel):
    video_id: str = Field(..., title='Video Id')


class PikaBodyGenerate22I2vGenerate22I2vPost(BaseModel):
    image: bytes = Field(..., title='Image')
    promptText: Optional[str] = Field(None, title='Prompttext')
    negativePrompt: Optional[str] = Field(None, title='Negativeprompt')
    seed: Optional[int] = Field(None, title='Seed')
    resolution: Optional[str] = Field('1080p', title='Resolution')
    duration: Optional[int] = Field(5, title='Duration')


class IngredientsMode(str, Enum):
    creative = 'creative'
    precise = 'precise'


class PikaBodyGenerate22C2vGenerate22PikascenesPost(BaseModel):
    images: List[bytes] = Field(
        ..., description='Array of images to process', title='Images'
    )
    ingredientsMode: IngredientsMode = Field(..., title='Ingredientsmode')
    promptText: Optional[str] = Field(None, title='Prompttext')
    negativePrompt: Optional[str] = Field(None, title='Negativeprompt')
    seed: Optional[int] = Field(None, title='Seed')
    resolution: Optional[str] = Field('1080p', title='Resolution')
    duration: Optional[int] = Field(5, title='Duration')
    aspectRatio: Optional[AspectRatio2] = Field(
        None, description='Aspect ratio (width / height)', title='Aspectratio'
    )


class PikaBodyGenerate22KeyframeGenerate22PikaframesPost(BaseModel):
    keyFrames: List[bytes] = Field(
        ..., description='Array of keyframe images', title='Keyframes'
    )
    promptText: str = Field(..., title='Prompttext')
    negativePrompt: Optional[str] = Field(None, title='Negativeprompt')
    seed: Optional[int] = Field(None, title='Seed')
    resolution: Optional[str] = Field('1080p', title='Resolution')
    duration: Optional[int] = Field(5, title='Duration')


class PikaVideoResponse(BaseModel):
    id: str = Field(..., title='Id')
    status: str = Field(..., title='Status')
    url: str = Field(..., title='Url')
    progress: int = Field(..., title='Progress')


class PikaValidationError(BaseModel):
    loc: List[Union[str, int]] = Field(..., title='Location')
    msg: str = Field(..., title='Message')
    type: str = Field(..., title='Error Type')


class RunwayImageToVideoRequest(BaseModel):
    promptImage: RunwayPromptImageObject
    seed: int = Field(
        ..., description='Random seed for generation', ge=0, le=4294967295
    )
    model: RunwayModelEnum = Field(..., description='Model to use for generation')
    promptText: Optional[str] = Field(
        None, description='Text prompt for the generation', max_length=1000
    )
    duration: RunwayDurationEnum = Field(
        ..., description='The number of seconds of duration for the output video.'
    )
    ratio: RunwayAspectRatioEnum = Field(
        ...,
        description='The resolution (aspect ratio) of the output video. Allowable values depend on the selected model. 1280:768 and 768:1280 are only supported for gen3a_turbo.',
    )


class RunwayTaskStatusResponse(BaseModel):
    id: Optional[str] = Field(None, description='Task ID')
    status: Optional[RunwayTaskStatusEnum] = Field(None, description='Task status')
    createdAt: Optional[datetime] = Field(None, description='Task creation timestamp')
    output: Optional[List[str]] = Field(None, description='Array of output video URLs')


class PikaHTTPValidationError(BaseModel):
    detail: Optional[List[PikaValidationError]] = Field(None, title='Detail')
