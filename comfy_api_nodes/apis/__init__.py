# generated by datamodel-codegen:
#   filename:  filtered-openapi.yaml
#   timestamp: 2025-05-01T05:55:00+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Literal, Optional, Union
from uuid import UUID

from pydantic import AnyUrl, BaseModel, Field, RootModel

bytes_aliased = bytes


class BFLFluxProGenerateRequest(BaseModel):
    guidance_scale: Optional[float] = Field(
        None, description="The guidance scale for generation.", ge=1.0, le=20.0
    )
    height: int = Field(
        ..., description="The height of the image to generate.", ge=64, le=2048
    )
    negative_prompt: Optional[str] = Field(
        None, description="The negative prompt for image generation."
    )
    num_images: Optional[int] = Field(
        None, description="The number of images to generate.", ge=1, le=4
    )
    num_inference_steps: Optional[int] = Field(
        None, description="The number of inference steps.", ge=1, le=100
    )
    prompt: str = Field(..., description="The text prompt for image generation.")
    seed: Optional[int] = Field(None, description="The seed value for reproducibility.")
    width: int = Field(
        ..., description="The width of the image to generate.", ge=64, le=2048
    )


class BFLFluxProGenerateResponse(BaseModel):
    id: str = Field(..., description="The unique identifier for the generation task.")
    polling_url: str = Field(..., description="URL to poll for the generation result.")


class ErrorResponse(BaseModel):
    error: str
    message: str


class IdeogramColorPalette1(BaseModel):
    name: str = Field(..., description="Name of the preset color palette")


class Member(BaseModel):
    color: Optional[str] = Field(
        None, description="Hexadecimal color code", pattern="^#[0-9A-Fa-f]{6}$"
    )
    weight: Optional[float] = Field(
        None, description="Optional weight for the color (0-1)", ge=0.0, le=1.0
    )


class IdeogramColorPalette2(BaseModel):
    members: List[Member] = Field(
        ..., description="Array of color definitions with optional weights"
    )


class IdeogramColorPalette(
    RootModel[Union[IdeogramColorPalette1, IdeogramColorPalette2]]
):
    root: Union[IdeogramColorPalette1, IdeogramColorPalette2] = Field(
        ...,
        description="A color palette specification that can either use a preset name or explicit color definitions with weights",
    )


class ImageRequest(BaseModel):
    aspect_ratio: Optional[str] = Field(
        None,
        description="Optional. The aspect ratio (e.g., 'ASPECT_16_9', 'ASPECT_1_1'). Cannot be used with resolution. Defaults to 'ASPECT_1_1' if unspecified.",
    )
    color_palette: Optional[Dict[str, Any]] = Field(
        None, description="Optional. Color palette object. Only for V_2, V_2_TURBO."
    )
    magic_prompt_option: Optional[str] = Field(
        None, description="Optional. MagicPrompt usage ('AUTO', 'ON', 'OFF')."
    )
    model: str = Field(..., description="The model used (e.g., 'V_2', 'V_2A_TURBO')")
    negative_prompt: Optional[str] = Field(
        None,
        description="Optional. Description of what to exclude. Only for V_1, V_1_TURBO, V_2, V_2_TURBO.",
    )
    num_images: Optional[int] = Field(
        1,
        description="Optional. Number of images to generate (1-8). Defaults to 1.",
        ge=1,
        le=8,
    )
    prompt: str = Field(
        ..., description="Required. The prompt to use to generate the image."
    )
    resolution: Optional[str] = Field(
        None,
        description="Optional. Resolution (e.g., 'RESOLUTION_1024_1024'). Only for model V_2. Cannot be used with aspect_ratio.",
    )
    seed: Optional[int] = Field(
        None,
        description="Optional. A number between 0 and 2147483647.",
        ge=0,
        le=2147483647,
    )
    style_type: Optional[str] = Field(
        None,
        description="Optional. Style type ('AUTO', 'GENERAL', 'REALISTIC', 'DESIGN', 'RENDER_3D', 'ANIME'). Only for models V_2 and above.",
    )


class IdeogramGenerateRequest(BaseModel):
    image_request: ImageRequest = Field(
        ..., description="The image generation request parameters."
    )


class Datum(BaseModel):
    is_image_safe: Optional[bool] = Field(
        None, description="Indicates whether the image is considered safe."
    )
    prompt: Optional[str] = Field(
        None, description="The prompt used to generate this image."
    )
    resolution: Optional[str] = Field(
        None, description="The resolution of the generated image (e.g., '1024x1024')."
    )
    seed: Optional[int] = Field(
        None, description="The seed value used for this generation."
    )
    style_type: Optional[str] = Field(
        None,
        description="The style type used for generation (e.g., 'REALISTIC', 'ANIME').",
    )
    url: Optional[str] = Field(None, description="URL to the generated image.")


class IdeogramGenerateResponse(BaseModel):
    created: Optional[datetime] = Field(
        None, description="Timestamp when the generation was created."
    )
    data: Optional[List[Datum]] = Field(
        None, description="Array of generated image information."
    )


class StyleCode(RootModel[str]):
    root: str = Field(..., pattern="^[0-9A-Fa-f]{8}$")


class ColorPalette(BaseModel):
    name: str = Field(..., description="Name of the color palette", examples=["PASTEL"])


class MagicPrompt(str, Enum):
    ON = "ON"
    OFF = "OFF"


class StyleType(str, Enum):
    GENERAL = "GENERAL"


class KlingErrorResponse(BaseModel):
    code: int = Field(
        ...,
        description="- 1000: Authentication failed\n- 1001: Authorization is empty\n- 1002: Authorization is invalid\n- 1003: Authorization is not yet valid\n- 1004: Authorization has expired\n- 1100: Account exception\n- 1101: Account in arrears (postpaid scenario)\n- 1102: Resource pack depleted or expired (prepaid scenario)\n- 1103: Unauthorized access to requested resource\n- 1200: Invalid request parameters\n- 1201: Invalid parameters\n- 1202: Invalid request method\n- 1203: Requested resource does not exist\n- 1300: Trigger platform strategy\n- 1301: Trigger content security policy\n- 1302: API request too frequent\n- 1303: Concurrency/QPS exceeds limit\n- 1304: Trigger IP whitelist policy\n- 5000: Internal server error\n- 5001: Service temporarily unavailable\n- 5002: Server internal timeout\n",
    )
    message: str = Field(..., description="Human-readable error message")
    request_id: str = Field(
        ..., description="Request ID for tracking and troubleshooting"
    )


class AspectRatio(str, Enum):
    field_16_9 = "16:9"
    field_9_16 = "9:16"
    field_1_1 = "1:1"


class Config(BaseModel):
    horizontal: Optional[float] = Field(
        None,
        description="Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right.",
        ge=-10.0,
        le=10.0,
    )
    pan: Optional[float] = Field(
        None,
        description="Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation.",
        ge=-10.0,
        le=10.0,
    )
    roll: Optional[float] = Field(
        None,
        description="Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise.",
        ge=-10.0,
        le=10.0,
    )
    tilt: Optional[float] = Field(
        None,
        description="Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation.",
        ge=-10.0,
        le=10.0,
    )
    vertical: Optional[float] = Field(
        None,
        description="Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward.",
        ge=-10.0,
        le=10.0,
    )
    zoom: Optional[float] = Field(
        None,
        description="Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view.",
        ge=-10.0,
        le=10.0,
    )


class Type(str, Enum):
    simple = "simple"
    down_back = "down_back"
    forward_up = "forward_up"
    right_turn_forward = "right_turn_forward"
    left_turn_forward = "left_turn_forward"


class CameraControl(BaseModel):
    config: Optional[Config] = None
    type: Optional[Type] = Field(
        None,
        description="Predefined camera movements type. simple: Customizable camera movement. down_back: Camera descends and moves backward. forward_up: Camera moves forward and tilts up. right_turn_forward: Rotate right and move forward. left_turn_forward: Rotate left and move forward.",
    )


class Duration(str, Enum):
    field_5 = "5"
    field_10 = "10"


class Trajectory(BaseModel):
    x: Optional[int] = Field(
        None,
        description="The horizontal coordinate of trajectory point. Based on bottom-left corner of image as origin (0,0).",
    )
    y: Optional[int] = Field(
        None,
        description="The vertical coordinate of trajectory point. Based on bottom-left corner of image as origin (0,0).",
    )


class DynamicMask(BaseModel):
    mask: Optional[AnyUrl] = Field(
        None,
        description="Dynamic Brush Application Area (Mask image created by users using the motion brush). The aspect ratio must match the input image.",
    )
    trajectories: Optional[List[Trajectory]] = None


class Mode(str, Enum):
    std = "std"
    pro = "pro"


class ModelName(str, Enum):
    kling_v1 = "kling-v1"
    kling_v1_5 = "kling-v1-5"
    kling_v1_6 = "kling-v1-6"
    kling_v2_master = "kling-v2-master"


class KlingImage2VideoRequest(BaseModel):
    aspect_ratio: Optional[AspectRatio] = "16:9"
    callback_url: Optional[AnyUrl] = Field(
        None,
        description="The callback notification address. Server will notify when the task status changes.",
    )
    camera_control: Optional[CameraControl] = None
    cfg_scale: Optional[float] = Field(
        0.5,
        description="Flexibility in video generation. The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
        ge=0.0,
        le=1.0,
    )
    duration: Optional[Duration] = Field("5", description="Video length in seconds")
    dynamic_masks: Optional[List[DynamicMask]] = Field(
        None,
        description="Dynamic Brush Configuration List (up to 6 groups). For 5-second videos, trajectory length must not exceed 77 coordinates.",
    )
    external_task_id: Optional[str] = Field(
        None,
        description="Customized Task ID. Must be unique within a single user account.",
    )
    image: Optional[str] = Field(
        None,
        description="Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix.",
    )
    image_tail: Optional[str] = Field(
        None,
        description="Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix.",
    )
    mode: Optional[Mode] = Field(
        "std",
        description="Video generation mode. std: Standard Mode, which is cost-effective. pro: Professional Mode, generates videos with longer duration but higher quality output.",
    )
    model_name: Optional[ModelName] = Field("kling-v1", description="Model Name")
    negative_prompt: Optional[str] = Field(
        None, description="Negative text prompt", max_length=2500
    )
    prompt: Optional[str] = Field(
        None, description="Positive text prompt", max_length=2500
    )
    static_mask: Optional[AnyUrl] = Field(
        None,
        description="Static Brush Application Area (Mask image created by users using the motion brush). The aspect ratio must match the input image.",
    )


class TaskInfo(BaseModel):
    external_task_id: Optional[str] = None


class Video(BaseModel):
    duration: Optional[str] = Field(None, description="Total video duration")
    id: Optional[str] = Field(None, description="Generated video ID")
    url: Optional[AnyUrl] = Field(None, description="URL for generated video")


class TaskResult(BaseModel):
    videos: Optional[List[Video]] = None


class TaskStatus(str, Enum):
    submitted = "submitted"
    processing = "processing"
    succeed = "succeed"
    failed = "failed"


class Data(BaseModel):
    created_at: Optional[int] = Field(None, description="Task creation time")
    task_id: Optional[str] = Field(None, description="Task ID")
    task_info: Optional[TaskInfo] = None
    task_result: Optional[TaskResult] = None
    task_status: Optional[TaskStatus] = None
    updated_at: Optional[int] = Field(None, description="Task update time")


class KlingImage2VideoResponse(BaseModel):
    code: Optional[int] = Field(None, description="Error code")
    data: Optional[Data] = None
    message: Optional[str] = Field(None, description="Error message")
    request_id: Optional[str] = Field(None, description="Request ID")


class Config1(BaseModel):
    horizontal: Optional[float] = Field(None, ge=-10.0, le=10.0)
    pan: Optional[float] = Field(None, ge=-10.0, le=10.0)
    roll: Optional[float] = Field(None, ge=-10.0, le=10.0)
    tilt: Optional[float] = Field(None, ge=-10.0, le=10.0)
    vertical: Optional[float] = Field(None, ge=-10.0, le=10.0)
    zoom: Optional[float] = Field(None, ge=-10.0, le=10.0)


class CameraControl1(BaseModel):
    config: Optional[Config1] = None
    type: Optional[Type] = Field(None, description="Predefined camera movements type")


class ModelName1(str, Enum):
    kling_v1 = "kling-v1"
    kling_v1_6 = "kling-v1-6"
    kling_v2_master = "kling-v2-master"


class KlingText2VideoRequest(BaseModel):
    aspect_ratio: Optional[AspectRatio] = "16:9"
    callback_url: Optional[AnyUrl] = Field(
        None, description="The callback notification address"
    )
    camera_control: Optional[CameraControl1] = None
    cfg_scale: Optional[float] = Field(
        0.5, description="Flexibility in video generation", ge=0.0, le=1.0
    )
    duration: Optional[Duration] = "5"
    external_task_id: Optional[str] = Field(None, description="Customized Task ID")
    mode: Optional[Mode] = Field("std", description="Video generation mode")
    model_name: Optional[ModelName1] = Field("kling-v1", description="Model Name")
    negative_prompt: Optional[str] = Field(
        None, description="Negative text prompt", max_length=2500
    )
    prompt: Optional[str] = Field(
        None, description="Positive text prompt", max_length=2500
    )


class TaskResult1(BaseModel):
    videos: Optional[List[Video]] = None


class Data1(BaseModel):
    created_at: Optional[int] = Field(None, description="Task creation time")
    task_id: Optional[str] = Field(None, description="Task ID")
    task_info: Optional[TaskInfo] = None
    task_result: Optional[TaskResult1] = None
    task_status: Optional[TaskStatus] = None
    updated_at: Optional[int] = Field(None, description="Task update time")


class KlingText2VideoResponse(BaseModel):
    code: Optional[int] = Field(None, description="Error code")
    data: Optional[Data1] = None
    message: Optional[str] = Field(None, description="Error message")
    request_id: Optional[str] = Field(None, description="Request ID")


class LumaAspectRatio(str, Enum):
    field_1_1 = "1:1"
    field_16_9 = "16:9"
    field_9_16 = "9:16"
    field_4_3 = "4:3"
    field_3_4 = "3:4"
    field_21_9 = "21:9"
    field_9_21 = "9:21"


class LumaAssets(BaseModel):
    image: Optional[AnyUrl] = Field(None, description="The URL of the image")
    progress_video: Optional[AnyUrl] = Field(
        None, description="The URL of the progress video"
    )
    video: Optional[AnyUrl] = Field(None, description="The URL of the video")


class GenerationType(str, Enum):
    add_audio = "add_audio"


class LumaAudioGenerationRequest(BaseModel):
    callback_url: Optional[AnyUrl] = Field(
        None, description="The callback URL for the audio"
    )
    generation_type: Optional[GenerationType] = "add_audio"
    negative_prompt: Optional[str] = Field(
        None, description="The negative prompt of the audio"
    )
    prompt: Optional[str] = Field(None, description="The prompt of the audio")


class LumaError(BaseModel):
    detail: Optional[str] = Field(None, description="The error message")


class Type2(str, Enum):
    generation = "generation"


class LumaGenerationReference(BaseModel):
    id: UUID = Field(..., description="The ID of the generation")
    type: Literal["generation"]


class GenerationType1(str, Enum):
    video = "video"


class LumaGenerationType(str, Enum):
    video = "video"
    image = "image"


class GenerationType2(str, Enum):
    image = "image"


class LumaImageIdentity(BaseModel):
    images: Optional[List[AnyUrl]] = Field(
        None, description="The URLs of the image identity"
    )


class LumaImageModel(str, Enum):
    photon_1 = "photon-1"
    photon_flash_1 = "photon-flash-1"


class LumaImageRef(BaseModel):
    url: Optional[AnyUrl] = Field(None, description="The URL of the image reference")
    weight: Optional[float] = Field(
        None, description="The weight of the image reference"
    )


class Type3(str, Enum):
    image = "image"


class LumaImageReference(BaseModel):
    type: Literal["image"]
    url: AnyUrl = Field(..., description="The URL of the image")


class LumaKeyframe(RootModel[Union[LumaGenerationReference, LumaImageReference]]):
    root: Union[LumaGenerationReference, LumaImageReference] = Field(
        ...,
        description="A keyframe can be either a Generation reference, an Image, or a Video",
        discriminator="type",
    )


class LumaKeyframes(BaseModel):
    frame0: Optional[LumaKeyframe] = None
    frame1: Optional[LumaKeyframe] = None


class LumaModifyImageRef(BaseModel):
    url: Optional[AnyUrl] = Field(None, description="The URL of the image reference")
    weight: Optional[float] = Field(
        None, description="The weight of the modify image reference"
    )


class LumaState(str, Enum):
    queued = "queued"
    dreaming = "dreaming"
    completed = "completed"
    failed = "failed"


class GenerationType3(str, Enum):
    upscale_video = "upscale_video"


class LumaVideoModel(str, Enum):
    ray_2 = "ray-2"
    ray_flash_2 = "ray-flash-2"
    ray_1_6 = "ray-1-6"


class LumaVideoModelOutputDuration1(str, Enum):
    field_5s = "5s"
    field_9s = "9s"


class LumaVideoModelOutputDuration(
    RootModel[Union[LumaVideoModelOutputDuration1, str]]
):
    root: Union[LumaVideoModelOutputDuration1, str]


class LumaVideoModelOutputResolution1(str, Enum):
    field_540p = "540p"
    field_720p = "720p"
    field_1080p = "1080p"
    field_4k = "4k"


class LumaVideoModelOutputResolution(
    RootModel[Union[LumaVideoModelOutputResolution1, str]]
):
    root: Union[LumaVideoModelOutputResolution1, str]


class MinimaxBaseResponse(BaseModel):
    status_code: int = Field(
        ...,
        description="Status code. 0 indicates success, other values indicate errors.",
    )
    status_msg: str = Field(
        ..., description="Specific error details or success message."
    )


class File(BaseModel):
    bytes: Optional[int] = Field(None, description="File size in bytes")
    created_at: Optional[int] = Field(
        None, description="Unix timestamp when the file was created, in seconds"
    )
    download_url: Optional[str] = Field(
        None, description="The URL to download the video"
    )
    file_id: Optional[int] = Field(None, description="Unique identifier for the file")
    filename: Optional[str] = Field(None, description="The name of the file")
    purpose: Optional[str] = Field(None, description="The purpose of using the file")


class MinimaxFileRetrieveResponse(BaseModel):
    base_resp: MinimaxBaseResponse
    file: File


class Status(str, Enum):
    Queueing = "Queueing"
    Preparing = "Preparing"
    Processing = "Processing"
    Success = "Success"
    Fail = "Fail"


class MinimaxTaskResultResponse(BaseModel):
    base_resp: MinimaxBaseResponse
    file_id: Optional[str] = Field(
        None,
        description="After the task status changes to Success, this field returns the file ID corresponding to the generated video.",
    )
    status: Status = Field(
        ...,
        description="Task status: 'Queueing' (in queue), 'Preparing' (task is preparing), 'Processing' (generating), 'Success' (task completed successfully), or 'Fail' (task failed).",
    )
    task_id: str = Field(..., description="The task ID being queried.")


class Model(str, Enum):
    T2V_01_Director = "T2V-01-Director"
    I2V_01_Director = "I2V-01-Director"
    S2V_01 = "S2V-01"
    I2V_01 = "I2V-01"
    I2V_01_live = "I2V-01-live"
    T2V_01 = "T2V-01"


class SubjectReferenceItem(BaseModel):
    image: Optional[str] = Field(
        None, description="URL or base64 encoding of the subject reference image."
    )
    mask: Optional[str] = Field(
        None,
        description="URL or base64 encoding of the mask for the subject reference image.",
    )


class MinimaxVideoGenerationRequest(BaseModel):
    callback_url: Optional[str] = Field(
        None,
        description="Optional. URL to receive real-time status updates about the video generation task.",
    )
    first_frame_image: Optional[str] = Field(
        None,
        description="URL or base64 encoding of the first frame image. Required when model is I2V-01, I2V-01-Director, or I2V-01-live.",
    )
    model: Model = Field(
        ...,
        description="Required. ID of model. Options: T2V-01-Director, I2V-01-Director, S2V-01, I2V-01, I2V-01-live, T2V-01",
    )
    prompt: Optional[str] = Field(
        None,
        description="Description of the video. Should be less than 2000 characters. Supports camera movement instructions in [brackets].",
        max_length=2000,
    )
    prompt_optimizer: Optional[bool] = Field(
        True,
        description="If true (default), the model will automatically optimize the prompt. Set to false for more precise control.",
    )
    subject_reference: Optional[List[SubjectReferenceItem]] = Field(
        None,
        description="Only available when model is S2V-01. The model will generate a video based on the subject uploaded through this parameter.",
    )


class MinimaxVideoGenerationResponse(BaseModel):
    base_resp: MinimaxBaseResponse
    task_id: str = Field(
        ..., description="The task ID for the asynchronous video generation task."
    )


class Moderation(str, Enum):
    low = "low"
    auto = "auto"


class OutputFormat(str, Enum):
    png = "png"
    webp = "webp"
    jpeg = "jpeg"


class OpenAIImageEditRequest(BaseModel):
    background: Optional[str] = Field(
        None, description="Background transparency", examples=["opaque"]
    )
    model: str = Field(
        ..., description="The model to use for image editing", examples=["gpt-image-1"]
    )
    moderation: Optional[Moderation] = Field(
        None, description="Content moderation setting", examples=["auto"]
    )
    n: Optional[int] = Field(
        None, description="The number of images to generate", examples=[1]
    )
    output_compression: Optional[int] = Field(
        None, description="Compression level for JPEG or WebP (0-100)", examples=[100]
    )
    output_format: Optional[OutputFormat] = Field(
        None, description="Format of the output image", examples=["png"]
    )
    prompt: str = Field(
        ...,
        description="A text description of the desired edit",
        examples=["Give the rocketship rainbow coloring"],
    )
    quality: Optional[str] = Field(
        None, description="The quality of the edited image", examples=["low"]
    )
    size: Optional[str] = Field(
        None, description="Size of the output image", examples=["1024x1024"]
    )
    user: Optional[str] = Field(
        None,
        description="A unique identifier for end-user monitoring",
        examples=["user-1234"],
    )


class Background(str, Enum):
    transparent = "transparent"
    opaque = "opaque"


class Quality(str, Enum):
    low = "low"
    medium = "medium"
    high = "high"
    standard = "standard"
    hd = "hd"


class ResponseFormat(str, Enum):
    url = "url"
    b64_json = "b64_json"


class Style(str, Enum):
    vivid = "vivid"
    natural = "natural"


class OpenAIImageGenerationRequest(BaseModel):
    background: Optional[Background] = Field(
        None, description="Background transparency", examples=["opaque"]
    )
    model: Optional[str] = Field(
        None, description="The model to use for image generation", examples=["dall-e-3"]
    )
    moderation: Optional[Moderation] = Field(
        None, description="Content moderation setting", examples=["auto"]
    )
    n: Optional[int] = Field(
        None,
        description="The number of images to generate (1-10). Only 1 supported for dall-e-3.",
        examples=[1],
    )
    output_compression: Optional[int] = Field(
        None, description="Compression level for JPEG or WebP (0-100)", examples=[100]
    )
    output_format: Optional[OutputFormat] = Field(
        None, description="Format of the output image", examples=["png"]
    )
    prompt: str = Field(
        ...,
        description="A text description of the desired image",
        examples=["Draw a rocket in front of a blackhole in deep space"],
    )
    quality: Optional[Quality] = Field(
        None, description="The quality of the generated image", examples=["high"]
    )
    response_format: Optional[ResponseFormat] = Field(
        None, description="Response format of image data", examples=["b64_json"]
    )
    size: Optional[str] = Field(
        None,
        description="Size of the image (e.g., 1024x1024, 1536x1024, auto)",
        examples=["1024x1536"],
    )
    style: Optional[Style] = Field(
        None, description="Style of the image (only for dall-e-3)", examples=["vivid"]
    )
    user: Optional[str] = Field(
        None,
        description="A unique identifier for end-user monitoring",
        examples=["user-1234"],
    )


class Datum1(BaseModel):
    b64_json: Optional[str] = Field(None, description="Base64 encoded image data")
    revised_prompt: Optional[str] = Field(None, description="Revised prompt")
    url: Optional[str] = Field(None, description="URL of the image")


class InputTokensDetails(BaseModel):
    image_tokens: Optional[int] = None
    text_tokens: Optional[int] = None


class Usage(BaseModel):
    input_tokens: Optional[int] = None
    input_tokens_details: Optional[InputTokensDetails] = None
    output_tokens: Optional[int] = None
    total_tokens: Optional[int] = None


class OpenAIImageGenerationResponse(BaseModel):
    data: Optional[List[Datum1]] = None
    usage: Optional[Usage] = None


class AspectRatio2(RootModel[float]):
    root: float = Field(
        ...,
        description="Aspect ratio (width / height)",
        ge=0.4,
        le=2.5,
        title="Aspectratio",
    )


class IngredientsMode(str, Enum):
    creative = "creative"
    precise = "precise"


class PikaDurationEnum(int, Enum):
    integer_5 = 5
    integer_10 = 10


class PikaGenerateResponse(BaseModel):
    video_id: str = Field(..., title="Video Id")


class PikaResolutionEnum(str, Enum):
    field_1080p = "1080p"
    field_720p = "720p"


class PikaStatusEnum(str, Enum):
    queued = "queued"
    started = "started"
    finished = "finished"


class PikaValidationError(BaseModel):
    loc: List[Union[str, int]] = Field(..., title="Location")
    msg: str = Field(..., title="Message")
    type: str = Field(..., title="Error Type")


class PikaVideoResponse(BaseModel):
    id: str = Field(..., title="Id")
    progress: Optional[int] = Field(None, title="Progress")
    status: PikaStatusEnum
    url: Optional[str] = Field(None, title="Url")


class Resp(BaseModel):
    img_id: Optional[int] = None


class PixverseImageUploadResponse(BaseModel):
    ErrCode: Optional[int] = None
    ErrMsg: Optional[str] = None
    Resp_1: Optional[Resp] = Field(None, alias="Resp")


class Duration2(int, Enum):
    integer_5 = 5
    integer_8 = 8


class Model1(str, Enum):
    v3_5 = "v3.5"


class MotionMode(str, Enum):
    normal = "normal"
    fast = "fast"


class Quality1(str, Enum):
    field_360p = "360p"
    field_540p = "540p"
    field_720p = "720p"
    field_1080p = "1080p"


class Style1(str, Enum):
    anime = "anime"
    field_3d_animation = "3d_animation"
    clay = "clay"
    comic = "comic"
    cyberpunk = "cyberpunk"


class PixverseImageVideoRequest(BaseModel):
    duration: Duration2
    img_id: int
    model: Model1
    motion_mode: Optional[MotionMode] = None
    prompt: str
    quality: Quality1
    seed: Optional[int] = None
    style: Optional[Style1] = None
    template_id: Optional[int] = None
    water_mark: Optional[bool] = None


class AspectRatio3(str, Enum):
    field_16_9 = "16:9"
    field_4_3 = "4:3"
    field_1_1 = "1:1"
    field_3_4 = "3:4"
    field_9_16 = "9:16"


class PixverseTextVideoRequest(BaseModel):
    aspect_ratio: AspectRatio3
    duration: Duration2
    model: Model1
    motion_mode: Optional[MotionMode] = None
    negative_prompt: Optional[str] = None
    prompt: str
    quality: Quality1
    seed: Optional[int] = None
    style: Optional[Style1] = None
    template_id: Optional[int] = None
    water_mark: Optional[bool] = None


class PixverseTransitionVideoRequest(BaseModel):
    duration: Duration2
    first_frame_img: int
    last_frame_img: int
    model: Model1
    motion_mode: MotionMode
    prompt: str
    quality: Quality1
    seed: int
    style: Optional[Style1] = None
    template_id: Optional[int] = None
    water_mark: Optional[bool] = None


class Resp1(BaseModel):
    video_id: Optional[int] = None


class PixverseVideoResponse(BaseModel):
    ErrCode: Optional[int] = None
    ErrMsg: Optional[str] = None
    Resp: Optional[Resp1] = None


class Status1(int, Enum):
    integer_1 = 1
    integer_5 = 5
    integer_6 = 6
    integer_7 = 7
    integer_8 = 8


class Resp2(BaseModel):
    create_time: Optional[str] = None
    id: Optional[int] = None
    modify_time: Optional[str] = None
    negative_prompt: Optional[str] = None
    outputHeight: Optional[int] = None
    outputWidth: Optional[int] = None
    prompt: Optional[str] = None
    resolution_ratio: Optional[int] = None
    seed: Optional[int] = None
    size: Optional[int] = None
    status: Optional[Status1] = Field(
        None,
        description="Video generation status codes:\n* 1 - Generation successful\n* 5 - Generating\n* 6 - Deleted\n* 7 - Contents moderation failed\n* 8 - Generation failed\n",
    )
    style: Optional[str] = None
    url: Optional[str] = None


class PixverseVideoResultResponse(BaseModel):
    ErrCode: Optional[int] = None
    ErrMsg: Optional[str] = None
    Resp: Optional[Resp2] = None


class RgbItem(RootModel[int]):
    root: int = Field(..., ge=0, le=255)


class RGBColor(BaseModel):
    rgb: List[RgbItem] = Field(..., max_length=3, min_length=3)


class Controls(BaseModel):
    artistic_level: Optional[int] = Field(
        None,
        description="Defines artistic tone of your image. At a simple level, the person looks straight at the camera in a static and clean style. Dynamic and eccentric levels introduce movement and creativity.",
        ge=0,
        le=5,
    )
    background_color: Optional[RGBColor] = None
    colors: Optional[List[RGBColor]] = Field(
        None, description="An array of preferable colors"
    )
    no_text: Optional[bool] = Field(None, description="Do not embed text layouts")


class RecraftImageGenerationRequest(BaseModel):
    controls: Optional[Controls] = Field(
        None, description="The controls for the generated image"
    )
    model: str = Field(
        ..., description='The model to use for generation (e.g., "recraftv3")'
    )
    n: int = Field(..., description="The number of images to generate", ge=1, le=4)
    prompt: str = Field(
        ..., description="The text prompt describing the image to generate"
    )
    size: str = Field(
        ..., description='The size of the generated image (e.g., "1024x1024")'
    )
    style: Optional[str] = Field(
        None,
        description='The style to apply to the generated image (e.g., "digital_illustration")',
    )
    style_id: Optional[str] = Field(
        None,
        description='The style ID to apply to the generated image (e.g., "123e4567-e89b-12d3-a456-426614174000"). If style_id is provided, style should not be provided.',
    )


class Datum2(BaseModel):
    image_id: Optional[str] = Field(
        None, description="Unique identifier for the generated image"
    )
    url: Optional[str] = Field(None, description="URL to access the generated image")


class RecraftImageGenerationResponse(BaseModel):
    created: int = Field(
        ..., description="Unix timestamp when the generation was created"
    )
    credits: int = Field(..., description="Number of credits used for the generation")
    data: List[Datum2] = Field(..., description="Array of generated image information")


class RenderingSpeed(str, Enum):
    BALANCED = "BALANCED"
    TURBO = "TURBO"
    QUALITY = "QUALITY"


class Veo2GenVidPollRequest(BaseModel):
    operationName: str = Field(
        ...,
        description="Full operation name (from predict response)",
        examples=[
            "projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/OPERATION_ID"
        ],
    )


class Error(BaseModel):
    code: Optional[int] = Field(None, description="Error code")
    message: Optional[str] = Field(None, description="Error message")


class Video2(BaseModel):
    bytesBase64Encoded: Optional[str] = Field(
        None, description="Base64-encoded video content"
    )
    gcsUri: Optional[str] = Field(None, description="Cloud Storage URI of the video")
    mimeType: Optional[str] = Field(None, description="Video MIME type")


class Response(BaseModel):
    field_type: Optional[str] = Field(
        None,
        alias="@type",
        examples=[
            "type.googleapis.com/cloud.ai.large_models.vision.GenerateVideoResponse"
        ],
    )
    raiMediaFilteredCount: Optional[int] = Field(
        None, description="Count of media filtered by responsible AI policies"
    )
    raiMediaFilteredReasons: Optional[List[str]] = Field(
        None, description="Reasons why media was filtered by responsible AI policies"
    )
    videos: Optional[List[Video2]] = None


class Veo2GenVidPollResponse(BaseModel):
    done: Optional[bool] = None
    error: Optional[Error] = Field(
        None, description="Error details if operation failed"
    )
    name: Optional[str] = None
    response: Optional[Response] = Field(
        None, description="The actual prediction response if done is true"
    )


class Image(BaseModel):
    bytesBase64Encoded: str
    gcsUri: Optional[str] = None
    mimeType: Optional[str] = None


class Image1(BaseModel):
    bytesBase64Encoded: Optional[str] = None
    gcsUri: str
    mimeType: Optional[str] = None


class Instance(BaseModel):
    image: Optional[Union[Image, Image1]] = Field(
        None, description="Optional image to guide video generation"
    )
    prompt: str = Field(..., description="Text description of the video")


class PersonGeneration(str, Enum):
    ALLOW = "ALLOW"
    BLOCK = "BLOCK"


class Parameters(BaseModel):
    aspectRatio: Optional[str] = Field(None, examples=["16:9"])
    durationSeconds: Optional[int] = None
    enhancePrompt: Optional[bool] = None
    negativePrompt: Optional[str] = None
    personGeneration: Optional[PersonGeneration] = None
    sampleCount: Optional[int] = None
    seed: Optional[int] = None
    storageUri: Optional[str] = Field(
        None, description="Optional Cloud Storage URI to upload the video"
    )


class Veo2GenVidRequest(BaseModel):
    instances: Optional[List[Instance]] = None
    parameters: Optional[Parameters] = None


class Veo2GenVidResponse(BaseModel):
    name: str = Field(
        ...,
        description="Operation resource name",
        examples=[
            "projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/a1b07c8e-7b5a-4aba-bb34-3e1ccb8afcc8"
        ],
    )


class IdeogramV3EditRequest(BaseModel):
    color_palette: Optional[IdeogramColorPalette] = None
    image: Optional[bytes_aliased] = Field(
        None,
        description="The image being edited (max size 10MB); only JPEG, WebP and PNG formats are supported at this time.",
    )
    magic_prompt: Optional[str] = Field(
        None,
        description="Determine if MagicPrompt should be used in generating the request or not.",
    )
    mask: Optional[bytes_aliased] = Field(
        None,
        description="A black and white image of the same size as the image being edited (max size 10MB). Black regions in the mask should match up with the regions of the image that you would like to edit; only JPEG, WebP and PNG formats are supported at this time.",
    )
    num_images: Optional[int] = Field(
        None, description="The number of images to generate."
    )
    prompt: str = Field(
        ..., description="The prompt used to describe the edited result."
    )
    rendering_speed: RenderingSpeed
    seed: Optional[int] = Field(
        None, description="Random seed. Set for reproducible generation."
    )
    style_codes: Optional[List[StyleCode]] = Field(
        None,
        description="A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style_type.",
    )
    style_reference_images: Optional[List[bytes_aliased]] = Field(
        None,
        description="A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format.",
    )


class IdeogramV3Request(BaseModel):
    aspect_ratio: Optional[str] = Field(
        None, description="Aspect ratio in format WxH", examples=["1x3"]
    )
    color_palette: Optional[ColorPalette] = None
    magic_prompt: Optional[MagicPrompt] = Field(
        None, description="Whether to enable magic prompt enhancement"
    )
    negative_prompt: Optional[str] = Field(
        None, description="Text prompt specifying what to avoid in the generation"
    )
    num_images: Optional[int] = Field(
        None, description="Number of images to generate", ge=1
    )
    prompt: str = Field(..., description="The text prompt for image generation")
    rendering_speed: RenderingSpeed
    resolution: Optional[str] = Field(
        None, description="Image resolution in format WxH", examples=["1280x800"]
    )
    seed: Optional[int] = Field(
        None, description="Seed value for reproducible generation"
    )
    style_codes: Optional[List[StyleCode]] = Field(
        None, description="Array of style codes in hexadecimal format"
    )
    style_reference_images: Optional[List[str]] = Field(
        None, description="Array of reference image URLs or identifiers"
    )
    style_type: Optional[StyleType] = Field(
        None, description="The type of style to apply"
    )


class LumaGenerationRequest(BaseModel):
    aspect_ratio: LumaAspectRatio
    callback_url: Optional[AnyUrl] = Field(
        None,
        description="The callback URL of the generation, a POST request with Generation object will be sent to the callback URL when the generation is dreaming, completed, or failed",
    )
    duration: LumaVideoModelOutputDuration
    generation_type: Optional[GenerationType1] = "video"
    keyframes: Optional[LumaKeyframes] = None
    loop: Optional[bool] = Field(None, description="Whether to loop the video")
    model: LumaVideoModel
    prompt: str = Field(..., description="The prompt of the generation")
    resolution: LumaVideoModelOutputResolution


class CharacterRef(BaseModel):
    identity0: Optional[LumaImageIdentity] = None


class LumaImageGenerationRequest(BaseModel):
    aspect_ratio: Optional[LumaAspectRatio] = "16:9"
    callback_url: Optional[AnyUrl] = Field(
        None, description="The callback URL for the generation"
    )
    character_ref: Optional[CharacterRef] = None
    generation_type: Optional[GenerationType2] = "image"
    image_ref: Optional[List[LumaImageRef]] = None
    model: Optional[LumaImageModel] = "photon-1"
    modify_image_ref: Optional[LumaModifyImageRef] = None
    prompt: Optional[str] = Field(None, description="The prompt of the generation")
    style_ref: Optional[List[LumaImageRef]] = None


class LumaUpscaleVideoGenerationRequest(BaseModel):
    callback_url: Optional[AnyUrl] = Field(
        None, description="The callback URL for the upscale"
    )
    generation_type: Optional[GenerationType3] = "upscale_video"
    resolution: Optional[LumaVideoModelOutputResolution] = None


class PikaBodyGenerate22C2vGenerate22PikascenesPost(BaseModel):
    aspectRatio: Optional[AspectRatio2] = Field(
        None, description="Aspect ratio (width / height)", title="Aspectratio"
    )
    duration: Optional[PikaDurationEnum] = 5
    images: Optional[List[bytes_aliased]] = Field(
        None, description="Array of images to process", title="Images"
    )
    ingredientsMode: IngredientsMode = Field(..., title="Ingredientsmode")
    negativePrompt: Optional[str] = Field(None, title="Negativeprompt")
    promptText: Optional[str] = Field(None, title="Prompttext")
    resolution: Optional[PikaResolutionEnum] = "1080p"
    seed: Optional[int] = Field(None, title="Seed")


class PikaBodyGenerate22I2vGenerate22I2vPost(BaseModel):
    duration: Optional[PikaDurationEnum] = 5
    image: Optional[str] = Field(None, title="Image")
    negativePrompt: Optional[str] = Field(None, title="Negativeprompt")
    promptText: Optional[str] = Field(None, title="Prompttext")
    resolution: Optional[PikaResolutionEnum] = "1080p"
    seed: Optional[int] = Field(None, title="Seed")


class PikaBodyGenerate22KeyframeGenerate22PikaframesPost(BaseModel):
    duration: Optional[int] = Field(None, ge=5, le=10, title="Duration")
    keyFrames: List[bytes_aliased] = Field(
        ..., description="Array of keyframe images", title="Keyframes"
    )
    negativePrompt: Optional[str] = Field(None, title="Negativeprompt")
    promptText: str = Field(..., title="Prompttext")
    resolution: Optional[PikaResolutionEnum] = "1080p"
    seed: Optional[int] = Field(None, title="Seed")


class PikaBodyGenerate22T2vGenerate22T2vPost(BaseModel):
    aspectRatio: Optional[float] = Field(
        1.7777777777777777,
        description="Aspect ratio (width / height)",
        ge=0.4,
        le=2.5,
        title="Aspectratio",
    )
    duration: Optional[PikaDurationEnum] = 5
    negativePrompt: Optional[str] = Field(None, title="Negativeprompt")
    promptText: str = Field(..., title="Prompttext")
    resolution: Optional[PikaResolutionEnum] = "1080p"
    seed: Optional[int] = Field(None, title="Seed")


class PikaHTTPValidationError(BaseModel):
    detail: Optional[List[PikaValidationError]] = Field(None, title="Detail")


class LumaGeneration(BaseModel):
    assets: Optional[LumaAssets] = None
    created_at: Optional[datetime] = Field(
        None, description="The date and time when the generation was created"
    )
    failure_reason: Optional[str] = Field(
        None, description="The reason for the state of the generation"
    )
    generation_type: Optional[LumaGenerationType] = None
    id: Optional[UUID] = Field(None, description="The ID of the generation")
    model: Optional[str] = Field(None, description="The model used for the generation")
    request: Optional[
        Union[
            LumaGenerationRequest,
            LumaImageGenerationRequest,
            LumaUpscaleVideoGenerationRequest,
            LumaAudioGenerationRequest,
        ]
    ] = Field(None, description="The request of the generation")
    state: Optional[LumaState] = None
